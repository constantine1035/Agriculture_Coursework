{
 "cells": [
  {
   "cell_type": "code",
   "id": "0d166662-7bfd-4f54-84ef-2127d2a10829",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "NUM_CLASSES    = 10       # including background=0\n",
    "VAL_IMAGES_DIR = \"./AgricultureVision/val/images/rgb\"\n",
    "VAL_MASKS_DIR  = \"./AgricultureVision/val/masks\"\n",
    "VAL_LABELS_DIR = \"./AgricultureVisionYOLO/val/labels\"\n",
    "\n",
    "YOLO_MODELS = [\n",
    "    \"YOLOSEG/YOLOn/best.pt\",\n",
    "    \"YOLOSEG/YOLOs/best.pt\",\n",
    "    \"YOLOSEG/YOLOm/best.pt\",\n",
    "    \"YOLOSEG/YOLOl/best.pt\",\n",
    "    \"YOLOSEG/YOLOx/best.pt\",\n",
    "]\n",
    "\n",
    "SMP_MODELS = [\n",
    "    \"smp_logs/best_Unet_resnet101.pth\",\n",
    "    \"smp_logs/best_Unet_resnet34.pth\",\n",
    "    \"smp_logs/best_Unet_timm-efficientnet-b4.pth\",\n",
    "    \"smp_logs/best_UnetPlusPlus_resnet101.pth\",\n",
    "    \"smp_logs/best_UnetPlusPlus_resnet34.pth\",\n",
    "    \"smp_logs/best_UnetPlusPlus_timm-efficientnet-b4.pth\",\n",
    "    \"smp_logs/best_FPN_resnet101.pth\",\n",
    "    \"smp_logs/best_FPN_resnet34.pth\",\n",
    "    \"smp_logs/best_FPN_timm-efficientnet-b4.pth\",\n",
    "    \"smp_logs/best_DeepLabV3_resnet34.pth\",\n",
    "    \"smp_logs/best_DeepLabV3_resnext101+32x8d.pth\",\n",
    "    \"smp_logs/best_DeepLabV3_timm-efficientnet-b4.pth\",\n",
    "    \"smp_logs/best_DeepLabV3Plus_resnet34.pth\",\n",
    "    \"smp_logs/best_DeepLabV3Plus_resnext101+32x8d.pth\",\n",
    "    \"smp_logs/best_DeepLabV3Plus_timm-efficientnet-b4.pth\",    \n",
    "]\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "VAL_TRANSFORM = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "class SMPValDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=VAL_TRANSFORM):\n",
    "        self.images     = sorted([f for f in os.listdir(images_dir)\n",
    "                                  if f.lower().endswith((\".jpg\", \".png\"))])\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir  = masks_dir\n",
    "        self.transform  = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fn = self.images[idx]\n",
    "        img_path  = os.path.join(self.images_dir, fn)\n",
    "        mask_path = os.path.join(self.masks_dir, fn.rsplit(\".\", 1)[0] + \".png\")\n",
    "\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        mask  = np.array(Image.open(mask_path))\n",
    "\n",
    "        augmented = self.transform(image=image, mask=mask)\n",
    "        image     = augmented[\"image\"]\n",
    "        mask      = augmented[\"mask\"].long()\n",
    "\n",
    "        return image, mask, fn\n",
    "\n",
    "\n",
    "class YOLOValDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels_dir, img_size=512):\n",
    "        self.images = sorted([f for f in os.listdir(images_dir) if f.lower().endswith((\".jpg\",\".png\"))])\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.img_size   = img_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        fn = self.images[i]\n",
    "        img = np.array(Image.open(os.path.join(self.images_dir, fn)).convert(\"RGB\"))\n",
    "        h,w = img.shape[:2]\n",
    "        scale = self.img_size / max(h,w)\n",
    "        img_resized = np.array(Image.fromarray(img).resize((int(w*scale),int(h*scale))))\n",
    "        padded = np.zeros((self.img_size,self.img_size,3),dtype=img.dtype)\n",
    "        padded[:img_resized.shape[0],:img_resized.shape[1]] = img_resized\n",
    "        img_tensor = torch.from_numpy(padded).permute(2,0,1).float()/255.0\n",
    "        return img_tensor, fn, (h,w,scale)\n",
    "\n",
    "def fast_confusion(gt_mask, pred_mask, nclass):\n",
    "    inds = gt_mask * nclass + pred_mask\n",
    "    cm = np.bincount(inds, minlength=nclass**2).reshape(nclass,nclass)\n",
    "    return cm\n",
    "\n",
    "def compute_segmentation_metrics(conf_matrix):\n",
    "    tp = np.diag(conf_matrix)\n",
    "    fp = conf_matrix.sum(axis=0) - tp\n",
    "    fn = conf_matrix.sum(axis=1) - tp\n",
    "    with np.errstate(divide=\"ignore\",invalid=\"ignore\"):\n",
    "        precision = tp / (tp+fp)\n",
    "        recall    = tp / (tp+fn)\n",
    "        iou       = tp / (tp + fp + fn)\n",
    "        f1        = 2*precision*recall/(precision+recall)\n",
    "    for arr in (precision,recall,iou,f1):\n",
    "        arr[np.isnan(arr)] = 0.0\n",
    "    return {\n",
    "        \"per_class_precision\": precision,\n",
    "        \"per_class_recall\": recall,\n",
    "        \"per_class_iou\": iou,\n",
    "        \"per_class_f1\": f1,\n",
    "        \"mean_precision\": np.mean(precision),\n",
    "        \"mean_recall\": np.mean(recall),\n",
    "        \"mean_iou\": np.mean(iou),\n",
    "        \"mean_f1\": np.mean(f1)\n",
    "    }\n",
    "\n",
    "def eval_smp_model(model_path, val_loader):\n",
    "    arch,enc = os.path.basename(model_path)[:-4].split(\"_\")[1:3]\n",
    "    enc = enc.replace(\"+\", \"_\")\n",
    "    net = smp.create_model(arch=arch, encoder_name=enc, encoder_weights=None,\n",
    "                           in_channels=3, classes=NUM_CLASSES).to(DEVICE)\n",
    "    net.load_state_dict(torch.load(model_path.replace(\"+\", \"_\"), map_location=DEVICE))\n",
    "    net.eval()\n",
    "    total_cm = np.zeros((NUM_CLASSES,NUM_CLASSES),dtype=np.int64)\n",
    "    with torch.no_grad():\n",
    "        for img, gt, _ in tqdm(val_loader, desc=f\"SMP:{os.path.basename(model_path)}\"):\n",
    "            img = img.to(DEVICE)\n",
    "            out = net(img)\n",
    "            pred = torch.argmax(out,dim=1).squeeze(0).cpu().numpy().ravel()\n",
    "            gt_flat = gt.ravel()\n",
    "            total_cm += fast_confusion(gt_flat,pred,NUM_CLASSES)\n",
    "    return compute_segmentation_metrics(total_cm)\n",
    "\n",
    "import cv2\n",
    "\n",
    "def eval_yolo_model(model_path, val_dataset):\n",
    "    yolo = YOLO(model_path)\n",
    "    total_cm = np.zeros((NUM_CLASSES, NUM_CLASSES), dtype=np.int64)\n",
    "\n",
    "    for img_tensor, fn, (h, w, scale) in tqdm(val_dataset, desc=f\"YOLO:{os.path.basename(model_path)}\"):\n",
    "        results = yolo.predict(source=img_tensor.unsqueeze(0), imgsz=val_dataset.img_size, verbose=False)\n",
    "        res = results[0]\n",
    "\n",
    "        ph, pw = int(h * scale), int(w * scale)\n",
    "        mask_pred = np.zeros((ph, pw), dtype=np.uint8)\n",
    "\n",
    "        if res.masks is not None and res.masks.data is not None:\n",
    "            masks = res.masks.data.cpu().numpy().astype(bool)  # (N, H, W)\n",
    "            classes = res.boxes.cls.cpu().numpy().astype(int)  # (N,)\n",
    "            for m, cls in zip(masks, classes):\n",
    "                mask_pred[m] = cls + 1\n",
    "\n",
    "        flat_pred = mask_pred[:h, :w].ravel()\n",
    "        gt_mask = np.array(\n",
    "            Image.open(os.path.join(VAL_MASKS_DIR, fn.rsplit(\".\", 1)[0] + \".png\"))\n",
    "        ).ravel()\n",
    "        total_cm += fast_confusion(gt_mask, flat_pred, NUM_CLASSES)\n",
    "\n",
    "    return compute_segmentation_metrics(total_cm)\n",
    "\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    smp_val = SMPValDataset(VAL_IMAGES_DIR, VAL_MASKS_DIR)\n",
    "    smp_loader = DataLoader(smp_val, batch_size=1, shuffle=False, num_workers=2)\n",
    "    smp_results = {}\n",
    "    for m in SMP_MODELS:\n",
    "        smp_results[m] = eval_smp_model(m, smp_loader)\n",
    "    \n",
    "    yolo_val = YOLOValDataset(VAL_IMAGES_DIR, VAL_LABELS_DIR, img_size=512)\n",
    "    yolo_results = {}\n",
    "    for m in YOLO_MODELS:\n",
    "        yolo_results[m] = eval_yolo_model(m, yolo_val)\n",
    "    \n",
    "    rows = []\n",
    "    for name, res in {**smp_results, **yolo_results}.items():\n",
    "        rows.append({\n",
    "            \"model\": name,\n",
    "            \"mean_iou\": res[\"mean_iou\"],\n",
    "            \"mean_f1\": res[\"mean_f1\"],\n",
    "            \"mean_precision\": res[\"mean_precision\"],\n",
    "            \"mean_recall\": res[\"mean_recall\"],\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(\"mean_iou\", ascending=False)\n",
    "    print(df.to_markdown(index=False))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80f561-92c0-4582-b8a8-298197632c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
